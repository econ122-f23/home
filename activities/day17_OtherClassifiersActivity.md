Other Classifiers
================
ECON 122
Day 17

## Example 1: Spam using k-nn

This example looks at a data set of about 4600 emails that are
classified as spam or not spam, along with over 50 variables measuring
different characteristic of the email. Details about these variables are
found on the [Spambase
example](http://archive.ics.uci.edu/ml/datasets/Spambase) on the machine
learning data archive. The dataset linked to below is a slightly cleaned
up version of this data. The only extra column in the data is `rgroup`
which is a randomly assigned grouping variable (groups 0 through 99).

Read the data in

``` r
> # tsv = tab separated values!
> spam <- read_delim("https://raw.githubusercontent.com/mgelman/data/master/spamD.txt", delim="\t", col_types = cols(spam = col_factor(levels=c("non-spam","spam")), .default = col_double()))
> glimpse(spam)
Rows: 4,601
Columns: 59
$ word.freq.make             <dbl> 0.00, 0.21, 0.06, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.address          <dbl> 0.64, 0.28, 0.00, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.all              <dbl> 0.64, 0.50, 0.71, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.3d               <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ word.freq.our              <dbl> 0.32, 0.14, 1.23, 0.63, 0.63, 1.85, 1.92, 1…
$ word.freq.over             <dbl> 0.00, 0.28, 0.19, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.remove           <dbl> 0.00, 0.21, 0.19, 0.31, 0.31, 0.00, 0.00, 0…
$ word.freq.internet         <dbl> 0.00, 0.07, 0.12, 0.63, 0.63, 1.85, 0.00, 1…
$ word.freq.order            <dbl> 0.00, 0.00, 0.64, 0.31, 0.31, 0.00, 0.00, 0…
$ word.freq.mail             <dbl> 0.00, 0.94, 0.25, 0.63, 0.63, 0.00, 0.64, 0…
$ word.freq.receive          <dbl> 0.00, 0.21, 0.38, 0.31, 0.31, 0.00, 0.96, 0…
$ word.freq.will             <dbl> 0.64, 0.79, 0.45, 0.31, 0.31, 0.00, 1.28, 0…
$ word.freq.people           <dbl> 0.00, 0.65, 0.12, 0.31, 0.31, 0.00, 0.00, 0…
$ word.freq.report           <dbl> 0.00, 0.21, 0.00, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.addresses        <dbl> 0.00, 0.14, 1.75, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.free             <dbl> 0.32, 0.14, 0.06, 0.31, 0.31, 0.00, 0.96, 0…
$ word.freq.business         <dbl> 0.00, 0.07, 0.06, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.email            <dbl> 1.29, 0.28, 1.03, 0.00, 0.00, 0.00, 0.32, 0…
$ word.freq.you              <dbl> 1.93, 3.47, 1.36, 3.18, 3.18, 0.00, 3.85, 0…
$ word.freq.credit           <dbl> 0.00, 0.00, 0.32, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.your             <dbl> 0.96, 1.59, 0.51, 0.31, 0.31, 0.00, 0.64, 0…
$ word.freq.font             <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ word.freq.000              <dbl> 0.00, 0.43, 1.16, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.money            <dbl> 0.00, 0.43, 0.06, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.hp               <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ word.freq.hpl              <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ word.freq.george           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ word.freq.650              <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.lab              <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ word.freq.labs             <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ word.freq.telnet           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ word.freq.857              <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ word.freq.data             <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.415              <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ word.freq.85               <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ word.freq.technology       <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.1999             <dbl> 0.00, 0.07, 0.00, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.parts            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ word.freq.pm               <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ word.freq.direct           <dbl> 0.00, 0.00, 0.06, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.cs               <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ word.freq.meeting          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ word.freq.original         <dbl> 0.00, 0.00, 0.12, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.project          <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.re               <dbl> 0.00, 0.00, 0.06, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.edu              <dbl> 0.00, 0.00, 0.06, 0.00, 0.00, 0.00, 0.00, 0…
$ word.freq.table            <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ word.freq.conference       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ char.freq.semi             <dbl> 0.000, 0.000, 0.010, 0.000, 0.000, 0.000, 0…
$ char.freq.lparen           <dbl> 0.000, 0.132, 0.143, 0.137, 0.135, 0.223, 0…
$ char.freq.lbrack           <dbl> 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0…
$ char.freq.bang             <dbl> 0.778, 0.372, 0.276, 0.137, 0.135, 0.000, 0…
$ char.freq.dollar           <dbl> 0.000, 0.180, 0.184, 0.000, 0.000, 0.000, 0…
$ char.freq.hash             <dbl> 0.000, 0.048, 0.010, 0.000, 0.000, 0.000, 0…
$ capital.run.length.average <dbl> 3.756, 5.114, 9.821, 3.537, 3.537, 3.000, 1…
$ capital.run.length.longest <dbl> 61, 101, 485, 40, 40, 15, 4, 11, 445, 43, 6…
$ capital.run.length.total   <dbl> 278, 1028, 2259, 191, 191, 54, 112, 49, 125…
$ spam                       <fct> spam, spam, spam, spam, spam, spam, spam, s…
$ rgroup                     <dbl> 52, 91, 49, 88, 73, 45, 93, 10, 60, 75, 90,…
```

Here we fit a k-nn classifier using the 57 quantitative predictors from
the spam data to an 80%/20% training and test set split. We used
![k=10](https://latex.codecogs.com/png.latex?k%3D10 "k=10").

``` r
> set.seed(7)
> n <- nrow(spam)
> train_index <- sample(1:n, size=round(.8*n))
> trainX <- spam %>% slice(train_index) %>% select(-rgroup, -spam)
> testX <- spam %>% slice(-train_index) %>% select(-rgroup, -spam)
> spam_knn1 <- knn(trainX, testX, cl= spam$spam[train_index], k=10)
```

#### Question 1

Compute the accuracy, error rate and recall for the 20% test set.

#### Question 2

Any statistical method that uses a distance metric can yield results
that are sensitive to the scale of the variables. In the k-nn we are
using a distance measure with the predictors. Use an `apply` command to
compute the sd of the 57 predictors. Are they similar or different in
value?

#### Question 3

We can use the `scale` function on a data frame to standardize each
column of the test and training sets. Verify that the sd of the scaled
training and test sets are now all equal to 1.

``` r
> trainX <- scale(trainX)
> testX <- scale(testX)
```

#### Question 4

Refit the k-nn classifier to the scaled predictor sets using
![k=10](https://latex.codecogs.com/png.latex?k%3D10 "k=10"). How have
accuracy, error and recall rates changed?

#### Question 5

Refit the k-nn classifier using the scaled predictors from question 4,
but this time let `k` vary from 1 to 30. Which value of k looks optimal
for this data?

- Note: Use the function below with `lapply` to get the predictions for
  each `k`
- Hint: Once you have all the predictions, bind them together and use a
  `group_by` to calcualte `accuracy` and `recall`. Then use a `gather`
  to help plot them

``` r
> k <- seq(1,50,by=3)
> k
 [1]  1  4  7 10 13 16 19 22 25 28 31 34 37 40 43 46 49
> knn_fn <- function(k)
+ {
+   data_frame(k=k, prediction = knn.cv(scaledX, cl= spam$spam, k=k), y=spam$spam)
+ }
```

## Example 2: Spam using tree methods

Let’s now consider tree-based methods for classifying spam. Let’s go
back to the original scale of the predictor variables (and incldue spam
in the training/test data frames):

We will also steal the formula from the logistic model from day 18:

``` r
> xvars <- str_c(names(spam)[1:57], collapse="+")
> myform <- as.formula(str_c("spam ~ ", xvars))
> myform
spam ~ word.freq.make + word.freq.address + word.freq.all + word.freq.3d + 
    word.freq.our + word.freq.over + word.freq.remove + word.freq.internet + 
    word.freq.order + word.freq.mail + word.freq.receive + word.freq.will + 
    word.freq.people + word.freq.report + word.freq.addresses + 
    word.freq.free + word.freq.business + word.freq.email + word.freq.you + 
    word.freq.credit + word.freq.your + word.freq.font + word.freq.000 + 
    word.freq.money + word.freq.hp + word.freq.hpl + word.freq.george + 
    word.freq.650 + word.freq.lab + word.freq.labs + word.freq.telnet + 
    word.freq.857 + word.freq.data + word.freq.415 + word.freq.85 + 
    word.freq.technology + word.freq.1999 + word.freq.parts + 
    word.freq.pm + word.freq.direct + word.freq.cs + word.freq.meeting + 
    word.freq.original + word.freq.project + word.freq.re + word.freq.edu + 
    word.freq.table + word.freq.conference + char.freq.semi + 
    char.freq.lparen + char.freq.lbrack + char.freq.bang + char.freq.dollar + 
    char.freq.hash + capital.run.length.average + capital.run.length.longest + 
    capital.run.length.total
```

#### Question 6

Fit a decision tree to training data then compute the accuracy, error
and recall for the test data. What predictors look to be the important
predictors of spam based on this tree?

#### Question 7

Fit a random forest model to the spam data using the `randomForest`
command. Use the default settings (with produce 500 trees with
![m \approx \sqrt{p}](https://latex.codecogs.com/png.latex?m%20%5Capprox%20%5Csqrt%7Bp%7D "m \approx \sqrt{p}")).
Compute the accuracy, error and recall for the test data. What
predictors look to be the important predictors of spam based on this
method? Are they similar to the variable found in question 6?
